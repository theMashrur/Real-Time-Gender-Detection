{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\r\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow.keras as keras\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "datagen = ImageDataGenerator(\r\n",
    "    samplewise_center=True,\r\n",
    "    width_shift_range=0.1,\r\n",
    "    height_shift_range=0.1,\r\n",
    "    zoom_range=0.1,\r\n",
    "    validation_split=0.2\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train = datagen.flow_from_directory(\r\n",
    "    'Datasets/faces',\r\n",
    "    target_size=(100, 100),\r\n",
    "    color_mode='rgb',\r\n",
    "    class_mode='categorical',\r\n",
    "    batch_size=32,\r\n",
    "    subset='training'\r\n",
    "    )\r\n",
    "\r\n",
    "valid = datagen.flow_from_directory(\r\n",
    "    'Datasets/faces',\r\n",
    "    target_size=(100, 100),\r\n",
    "    color_mode = 'rgb',\r\n",
    "    class_mode='categorical',\r\n",
    "    batch_size=32,\r\n",
    "    subset = 'validation'\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 21735 images belonging to 2 classes.\n",
      "Found 5432 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import (\r\n",
    "    Dense,\r\n",
    "    Conv2D,\r\n",
    "    MaxPool2D,\r\n",
    "    Flatten,\r\n",
    "    Dropout,\r\n",
    "    BatchNormalization\r\n",
    ")\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", input_shape=(100, 100, 3)))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\r\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation='relu'))\r\n",
    "model.add(Dropout(0.2))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPool2D((2, 2,), strides=2, padding=\"same\"))\r\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation='relu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(units=512, activation='relu'))\r\n",
    "model.add(Dropout(0.3))\r\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "history = model.fit(train, epochs=20, validation_data=valid, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "680/680 [==============================] - 98s 131ms/step - loss: 0.5186 - accuracy: 0.7728 - val_loss: 0.4229 - val_accuracy: 0.8023\n",
      "Epoch 2/20\n",
      "680/680 [==============================] - 81s 117ms/step - loss: 0.3851 - accuracy: 0.8285 - val_loss: 0.3535 - val_accuracy: 0.8444\n",
      "Epoch 3/20\n",
      "680/680 [==============================] - 79s 114ms/step - loss: 0.3074 - accuracy: 0.8701 - val_loss: 0.2838 - val_accuracy: 0.8835\n",
      "Epoch 4/20\n",
      "680/680 [==============================] - 80s 116ms/step - loss: 0.2673 - accuracy: 0.8900 - val_loss: 0.2411 - val_accuracy: 0.9092\n",
      "Epoch 5/20\n",
      "680/680 [==============================] - 75s 109ms/step - loss: 0.2358 - accuracy: 0.9053 - val_loss: 0.2554 - val_accuracy: 0.8969\n",
      "Epoch 6/20\n",
      "680/680 [==============================] - 74s 108ms/step - loss: 0.2208 - accuracy: 0.9127 - val_loss: 0.2312 - val_accuracy: 0.9067\n",
      "Epoch 7/20\n",
      "680/680 [==============================] - 74s 107ms/step - loss: 0.2051 - accuracy: 0.9169 - val_loss: 0.2599 - val_accuracy: 0.9002\n",
      "Epoch 8/20\n",
      "680/680 [==============================] - 75s 108ms/step - loss: 0.1962 - accuracy: 0.9213 - val_loss: 0.2644 - val_accuracy: 0.8997\n",
      "Epoch 9/20\n",
      "680/680 [==============================] - 74s 106ms/step - loss: 0.1924 - accuracy: 0.9247 - val_loss: 0.2307 - val_accuracy: 0.9168\n",
      "Epoch 10/20\n",
      "680/680 [==============================] - 74s 108ms/step - loss: 0.1836 - accuracy: 0.9276 - val_loss: 0.2027 - val_accuracy: 0.9243\n",
      "Epoch 11/20\n",
      "680/680 [==============================] - 75s 108ms/step - loss: 0.1702 - accuracy: 0.9341 - val_loss: 0.2300 - val_accuracy: 0.9159\n",
      "Epoch 12/20\n",
      "680/680 [==============================] - 74s 108ms/step - loss: 0.1707 - accuracy: 0.9346 - val_loss: 0.2279 - val_accuracy: 0.9164\n",
      "Epoch 13/20\n",
      "680/680 [==============================] - 75s 108ms/step - loss: 0.1636 - accuracy: 0.9385 - val_loss: 0.2046 - val_accuracy: 0.9277\n",
      "Epoch 14/20\n",
      "680/680 [==============================] - 76s 111ms/step - loss: 0.1579 - accuracy: 0.9384 - val_loss: 0.2061 - val_accuracy: 0.9280\n",
      "Epoch 15/20\n",
      "680/680 [==============================] - 76s 110ms/step - loss: 0.1541 - accuracy: 0.9413 - val_loss: 0.2025 - val_accuracy: 0.9308\n",
      "Epoch 16/20\n",
      "680/680 [==============================] - 75s 109ms/step - loss: 0.1471 - accuracy: 0.9435 - val_loss: 0.2217 - val_accuracy: 0.9284\n",
      "Epoch 17/20\n",
      "680/680 [==============================] - 74s 108ms/step - loss: 0.1481 - accuracy: 0.9448 - val_loss: 0.2043 - val_accuracy: 0.9302\n",
      "Epoch 18/20\n",
      "680/680 [==============================] - 74s 107ms/step - loss: 0.1433 - accuracy: 0.9469 - val_loss: 0.2178 - val_accuracy: 0.9247\n",
      "Epoch 19/20\n",
      "680/680 [==============================] - 74s 108ms/step - loss: 0.1423 - accuracy: 0.9465 - val_loss: 0.2119 - val_accuracy: 0.9212\n",
      "Epoch 20/20\n",
      "680/680 [==============================] - 74s 107ms/step - loss: 0.1371 - accuracy: 0.9476 - val_loss: 0.2065 - val_accuracy: 0.9304\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model.save(\"gender_classifier\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: gender_classifier\\assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import IPython\r\n",
    "\r\n",
    "app = IPython.Application.instance()\r\n",
    "app.kernel.do_shutdown(True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}