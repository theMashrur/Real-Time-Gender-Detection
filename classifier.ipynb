{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\r\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow.keras as keras\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "datagen = ImageDataGenerator(\r\n",
    "    samplewise_center=True,\r\n",
    "    width_shift_range=0.1,\r\n",
    "    height_shift_range=0.1,\r\n",
    "    zoom_range=0.1,\r\n",
    "    validation_split=0.2\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train = datagen.flow_from_directory(\r\n",
    "    'Datasets/faces',\r\n",
    "    target_size=(100, 100),\r\n",
    "    color_mode='rgb',\r\n",
    "    class_mode='categorical',\r\n",
    "    batch_size=32,\r\n",
    "    subset='training'\r\n",
    "    )\r\n",
    "\r\n",
    "valid = datagen.flow_from_directory(\r\n",
    "    'Datasets/faces',\r\n",
    "    target_size=(100, 100),\r\n",
    "    color_mode = 'rgb',\r\n",
    "    class_mode='categorical',\r\n",
    "    batch_size=32,\r\n",
    "    subset = 'validation'\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 21735 images belonging to 2 classes.\n",
      "Found 5432 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import (\r\n",
    "    Dense,\r\n",
    "    Conv2D,\r\n",
    "    MaxPool2D,\r\n",
    "    Flatten,\r\n",
    "    Dropout,\r\n",
    "    BatchNormalization\r\n",
    ")\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", input_shape=(100, 100, 3)))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\r\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation='relu'))\r\n",
    "model.add(Dropout(0.2))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPool2D((2, 2,), strides=2, padding=\"same\"))\r\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation='relu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(units=512, activation='relu'))\r\n",
    "model.add(Dropout(0.3))\r\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "history = model.fit(train, epochs=20, validation_data=valid, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "680/680 [==============================] - 75s 106ms/step - loss: 0.5326 - accuracy: 0.7694 - val_loss: 0.3898 - val_accuracy: 0.8290\n",
      "Epoch 2/20\n",
      "680/680 [==============================] - 71s 104ms/step - loss: 0.3794 - accuracy: 0.8304 - val_loss: 0.3183 - val_accuracy: 0.8693\n",
      "Epoch 3/20\n",
      "680/680 [==============================] - 71s 104ms/step - loss: 0.3234 - accuracy: 0.8609 - val_loss: 0.3264 - val_accuracy: 0.8687\n",
      "Epoch 4/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.2901 - accuracy: 0.8763 - val_loss: 0.2935 - val_accuracy: 0.8765\n",
      "Epoch 5/20\n",
      "680/680 [==============================] - 71s 104ms/step - loss: 0.2484 - accuracy: 0.8987 - val_loss: 0.2383 - val_accuracy: 0.9032\n",
      "Epoch 6/20\n",
      "680/680 [==============================] - 71s 104ms/step - loss: 0.2314 - accuracy: 0.9047 - val_loss: 0.2426 - val_accuracy: 0.9102\n",
      "Epoch 7/20\n",
      "680/680 [==============================] - 74s 109ms/step - loss: 0.2095 - accuracy: 0.9180 - val_loss: 0.2187 - val_accuracy: 0.9124\n",
      "Epoch 8/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.2009 - accuracy: 0.9216 - val_loss: 0.2235 - val_accuracy: 0.9138\n",
      "Epoch 9/20\n",
      "680/680 [==============================] - 71s 104ms/step - loss: 0.1938 - accuracy: 0.9252 - val_loss: 0.2351 - val_accuracy: 0.9175\n",
      "Epoch 10/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.1842 - accuracy: 0.9291 - val_loss: 0.2207 - val_accuracy: 0.9133\n",
      "Epoch 11/20\n",
      "680/680 [==============================] - 71s 104ms/step - loss: 0.1736 - accuracy: 0.9326 - val_loss: 0.2400 - val_accuracy: 0.9188\n",
      "Epoch 12/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.1705 - accuracy: 0.9337 - val_loss: 0.2014 - val_accuracy: 0.9277\n",
      "Epoch 13/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.1603 - accuracy: 0.9394 - val_loss: 0.2304 - val_accuracy: 0.9157\n",
      "Epoch 14/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.1518 - accuracy: 0.9420 - val_loss: 0.2049 - val_accuracy: 0.9247\n",
      "Epoch 15/20\n",
      "680/680 [==============================] - 74s 108ms/step - loss: 0.1524 - accuracy: 0.9428 - val_loss: 0.1981 - val_accuracy: 0.9306\n",
      "Epoch 16/20\n",
      "680/680 [==============================] - 72s 107ms/step - loss: 0.1490 - accuracy: 0.9441 - val_loss: 0.2012 - val_accuracy: 0.9267\n",
      "Epoch 17/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.1410 - accuracy: 0.9473 - val_loss: 0.1876 - val_accuracy: 0.9317\n",
      "Epoch 18/20\n",
      "680/680 [==============================] - 72s 105ms/step - loss: 0.1368 - accuracy: 0.9486 - val_loss: 0.2038 - val_accuracy: 0.9321\n",
      "Epoch 19/20\n",
      "680/680 [==============================] - 71s 105ms/step - loss: 0.1353 - accuracy: 0.9500 - val_loss: 0.2579 - val_accuracy: 0.9177\n",
      "Epoch 20/20\n",
      "680/680 [==============================] - 72s 105ms/step - loss: 0.1293 - accuracy: 0.9522 - val_loss: 0.2205 - val_accuracy: 0.9205\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model.save(\"gender_classifier.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import IPython\r\n",
    "\r\n",
    "app = IPython.Application.instance()\r\n",
    "app.kernel.do_shutdown(True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\r\n",
    "\r\n",
    "def load_and_scale_image(image_path):\r\n",
    "    image = image_utils.load_img(image_path, color_mode=\"rgb\", target_size=(100, 100))\r\n",
    "    return image\r\n",
    "\r\n",
    "\r\n",
    "#model1 = keras.models.load_model('./gender_classifier.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "image = load_and_scale_image('./Datasets/faces/woman/woman_0.jpg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from numpy import argmax\r\n",
    "\r\n",
    "image = image_utils.img_to_array(image)\r\n",
    "image = image.reshape(1, 100, 100, 3)\r\n",
    "image = image/255\r\n",
    "prediction = model.predict(image)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "prediction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.00869255, 0.99130744]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}